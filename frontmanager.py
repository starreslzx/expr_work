import streamlit as st
import pandas as pd
import json
import plotly.graph_objects as go
import networkx as nx
import os
import sys
import tempfile
import uuid
from datetime import datetime

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from api_use import ChatAnalyzer  # åˆ†å·¥1

    DIVISION_1_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥åˆ†å·¥1æ¨¡å—")
except ImportError as e:
    DIVISION_1_AVAILABLE = False
    print(f"âš ï¸ æ— æ³•å¯¼å…¥åˆ†å·¥1æ¨¡å—: {e}")
    ChatAnalyzer = None

try:
    from Searcher import Searcher  # åˆ†å·¥3

    DIVISION_3_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥åˆ†å·¥3æ¨¡å—")
except ImportError as e:
    DIVISION_3_AVAILABLE = False
    print(f"âš ï¸ æ— æ³•å¯¼å…¥åˆ†å·¥3æ¨¡å—: {e}")
    Searcher = None

try:
    from graphs import TopicGraph  # åˆ†å·¥4

    DIVISION_4_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥åˆ†å·¥4æ¨¡å—")
except ImportError as e:
    DIVISION_4_AVAILABLE = False
    print(f"âš ï¸ æ— æ³•å¯¼å…¥åˆ†å·¥4æ¨¡å—: {e}")
    TopicGraph = None


class FrontendManager:
    def __init__(self):
        # åˆå§‹åŒ–session state
        self._init_session_state()

        # åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
        self._init_directory_structure()

        # åŠ è½½é…ç½®
        self.config = self._load_config()

        # åˆå§‹åŒ–å„æ¨¡å—å®ä¾‹
        self.analyzer = None  # åˆ†å·¥1å®ä¾‹
        self.searcher = None  # åˆ†å·¥3å®ä¾‹
        self.topic_graph = None  # åˆ†å·¥4å®ä¾‹

        # åˆå§‹åŒ–æ¨¡å—
        self.init_modules()

    def _init_session_state(self):
        """åˆå§‹åŒ–session state"""
        session_defaults = {
            'current_topic': None,
            'edit_mode': False,
            'uploaded_file': None,
            'analysis_data': None,
            'current_group': None,
            'topic_mapping': {},
            'data_file': None,
            'api_key': "",
            'base_url': "https://api-inference.modelscope.cn/v1/",
            'analyzer_instance': None,  # å­˜å‚¨åˆ†å·¥1å®ä¾‹
            'searcher_instance': None,  # å­˜å‚¨åˆ†å·¥3å®ä¾‹
            'topic_graph_instance': None,  # å­˜å‚¨åˆ†å·¥4å®ä¾‹
            'modules_initialized': False,  # æ¨¡å—æ˜¯å¦å·²åˆå§‹åŒ–
            'custom_group_name': "",
            'analysis_history': [],
            'selected_group_for_deletion': None,
            'graph_group_select': None,
            'last_search_topic': None,
            'search_expanded_topic_id': None,
            'search_topic_details': {},
        }

        for key, default in session_defaults.items():
            if key not in st.session_state:
                st.session_state[key] = default

    def _init_directory_structure(self):
        """åˆå§‹åŒ–é¡¹ç›®ç›®å½•ç»“æ„"""
        # ä¿®æ”¹ï¼šåˆ›å»ºç»Ÿä¸€çš„ç›®å½•ç»“æ„
        directories = ['output', 'config', 'reports', 'temp']
        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory, exist_ok=True)

        # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
        config_file = 'config/api_config.json'
        if not os.path.exists(config_file):
            default_config = {
                "api_key": "",
                "base_url": "https://api-inference.modelscope.cn/v1/",
                "model": "Qwen/Qwen2.5-7B-Instruct"
            }
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=2)

        # åˆ›å»ºAPIä»¤ç‰Œæ–‡ä»¶
        token_file = 'config/api_token.txt'
        if not os.path.exists(token_file):
            with open(token_file, 'w', encoding='utf-8') as f:
                f.write("")

    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            config_file = 'config/api_config.json'
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                # æ›´æ–°session stateä¸­çš„APIé…ç½®
                st.session_state.api_key = config.get("api_key", "")
                st.session_state.base_url = config.get("base_url",
                                                       "https://api-inference.modelscope.cn/v1/")
                return config
            return {}
        except Exception as e:
            st.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return {}

    def init_modules(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—"""
        # åˆå§‹åŒ–åˆ†å·¥1æ¨¡å—ï¼ˆèŠå¤©è®°å½•åˆ†æï¼‰
        if DIVISION_1_AVAILABLE and st.session_state.api_key:
            try:
                st.session_state.analyzer_instance = ChatAnalyzer(
                    api_key=st.session_state.api_key,
                    base_url=st.session_state.base_url
                )
                self.analyzer = st.session_state.analyzer_instance
                print("âœ… åˆ†å·¥1æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ åˆ†å·¥1æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
                self.analyzer = None
        else:
            self.analyzer = None
            if not DIVISION_1_AVAILABLE:
                print("âš ï¸ åˆ†å·¥1æ¨¡å—ä¸å¯ç”¨")
            else:
                print("âš ï¸ åˆ†å·¥1æ¨¡å—æœªåˆå§‹åŒ–ï¼ˆç¼ºå°‘APIå¯†é’¥ï¼‰")

        # åˆå§‹åŒ–åˆ†å·¥3æ¨¡å—ï¼ˆæ™ºèƒ½æœç´¢ï¼‰
        if DIVISION_3_AVAILABLE:
            try:
                # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                data_file = "output/search_data.json"
                token_file = "config/api_token.txt"

                # å¦‚æœæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„
                if not os.path.exists(data_file):
                    with open(data_file, 'w', encoding='utf-8') as f:
                        json.dump({"chat_groups": []}, f)

                st.session_state.searcher_instance = Searcher(
                    data_file=data_file,
                    token_file=token_file
                )
                self.searcher = st.session_state.searcher_instance
                print("âœ… åˆ†å·¥3æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ åˆ†å·¥3æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
                self.searcher = None
        else:
            self.searcher = None
            print("âš ï¸ åˆ†å·¥3æ¨¡å—ä¸å¯ç”¨")

        # åˆå§‹åŒ–åˆ†å·¥4æ¨¡å—
        if DIVISION_4_AVAILABLE:
            try:
                # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                graph_file = "output/topic_graph_data.json"
                if not os.path.exists(graph_file):
                    with open(graph_file, 'w', encoding='utf-8') as f:
                        json.dump({"chat_groups": []}, f)

                st.session_state.topic_graph_instance = TopicGraph(graph_file)
                self.topic_graph = st.session_state.topic_graph_instance
                print("âœ… åˆ†å·¥4æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ åˆ†å·¥4æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
                self.topic_graph = None
        else:
            self.topic_graph = None
            print("âš ï¸ åˆ†å·¥4æ¨¡å—ä¸å¯ç”¨")

        st.session_state.modules_initialized = True

    def handle_file_upload(self):
        """å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„èŠå¤©è®°å½•æ–‡ä»¶"""
        st.sidebar.markdown("### ğŸ“ ä¸Šä¼ èŠå¤©è®°å½•")

        # APIé…ç½®éƒ¨åˆ†
        st.sidebar.markdown("### ğŸ”‘ APIé…ç½®")
        col1, col2 = st.sidebar.columns([3, 1])

        with col1:
            api_key = st.text_input(
                "APIå¯†é’¥",
                value=st.session_state.api_key,
                type="password",
                help="è¾“å…¥Modelscope APIå¯†é’¥",
                key="api_key_input"
            )

        with col2:
            base_url = st.text_input(
                "APIåœ°å€",
                value=st.session_state.base_url,
                help="APIåŸºç¡€åœ°å€",
                key="base_url_input"
            )

        # æ£€æŸ¥APIé…ç½®æ˜¯å¦å˜åŒ–
        if api_key != st.session_state.api_key or base_url != st.session_state.base_url:
            st.session_state.api_key = api_key
            st.session_state.base_url = base_url
            # ä¿å­˜é…ç½®
            self._save_api_config(api_key, base_url)
            # é‡æ–°åˆå§‹åŒ–æ¨¡å—
            self.init_modules()
            st.rerun()

        # æ˜¾ç¤ºæ¨¡å—çŠ¶æ€
        self._show_module_status_in_sidebar()

        uploaded_file = st.sidebar.file_uploader(
            "é€‰æ‹©èŠå¤©è®°å½•æ–‡ä»¶",
            type=['txt', 'pdf', 'doc', 'docx'],
            help="æ”¯æŒTXTã€PDFã€DOCã€DOCXæ ¼å¼çš„èŠå¤©è®°å½•æ–‡ä»¶",
            key="file_uploader"
        )

        if uploaded_file is not None:
            st.session_state.uploaded_file = uploaded_file

            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            file_details = {
                "æ–‡ä»¶å": uploaded_file.name,
                "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024:.1f} KB",
                "æ–‡ä»¶ç±»å‹": uploaded_file.type.split('/')[-1].upper()
            }
            st.sidebar.write("æ–‡ä»¶ä¿¡æ¯:")
            for key, value in file_details.items():
                st.sidebar.write(f"- {key}: {value}")

            # æ–‡ä»¶å†…å®¹é¢„è§ˆï¼ˆä»…æ–‡æœ¬æ–‡ä»¶ï¼‰
            if uploaded_file.type.startswith('text/'):
                try:
                    content = uploaded_file.getvalue().decode('utf-8')
                    preview_lines = content.split('\n')[:5]
                    if any(line.strip() for line in preview_lines):
                        st.sidebar.write("**å†…å®¹é¢„è§ˆ:**")
                        for line in preview_lines:
                            if line.strip():
                                st.sidebar.text(line[:50] + "..." if len(line) > 50 else line)
                except:
                    pass

        # ç¾¤èŠåç§°è‡ªå®šä¹‰
        st.sidebar.markdown("### ğŸ·ï¸ ç¾¤èŠè®¾ç½®")
        default_group_name = f"èŠå¤©è®°å½•_{os.path.splitext(uploaded_file.name)[0]}" if uploaded_file else "é»˜è®¤ç¾¤èŠ"
        custom_group_name = st.sidebar.text_input(
            "ç¾¤èŠåç§°",
            value=st.session_state.custom_group_name or default_group_name,
            help="è‡ªå®šä¹‰ç¾¤èŠåç§°",
            key="custom_group_name_input"
        )
        st.session_state.custom_group_name = custom_group_name

        # è§¦å‘åˆ†ææŒ‰é’®
        if st.sidebar.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", key="analyze_button"):
            if not self.analyzer:
                st.sidebar.error("è¯·å…ˆè®¾ç½®æ­£ç¡®çš„APIå¯†é’¥")
            elif not uploaded_file:
                st.sidebar.error("è¯·å…ˆä¸Šä¼ èŠå¤©è®°å½•æ–‡ä»¶")
            else:
                with st.spinner("æ­£åœ¨åˆ†æèŠå¤©è®°å½•ï¼Œè¯·ç¨å€™..."):
                    # ç›´æ¥è°ƒç”¨åˆ†å·¥1çš„åˆ†ææ–¹æ³•
                    analysis_result = self._direct_analyze_file(uploaded_file, custom_group_name)
                    if analysis_result:
                        st.session_state.analysis_data = analysis_result
                        # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªç¾¤èŠ
                        if analysis_result.get("chat_groups"):
                            st.session_state.current_group = analysis_result["chat_groups"][0]["group_id"]
                        # æ„å»ºè¯é¢˜æ˜ å°„
                        self._build_topic_mapping()
                        # ä¿å­˜æ•°æ®ä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
                        self._save_data_to_files()
                        # é‡æ–°åˆå§‹åŒ–æ¨¡å—ä»¥åŠ è½½æ–°æ•°æ®
                        self.init_modules()
                        st.sidebar.success("åˆ†æå®Œæˆ")
                        st.rerun()
                    else:
                        st.sidebar.error("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–é‡è¯•")

        return uploaded_file

    def _show_module_status_in_sidebar(self):
        """åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ¨¡å—çŠ¶æ€"""
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ”§ æ¨¡å—çŠ¶æ€")

        # åˆ†å·¥1çŠ¶æ€
        if self.analyzer:
            st.sidebar.success("âœ… åˆ†ææ¨¡å—: å·²åŠ è½½")
        else:
            st.sidebar.warning("âš ï¸ åˆ†ææ¨¡å—: æœªåŠ è½½")

        # åˆ†å·¥3çŠ¶æ€
        if self.searcher:
            st.sidebar.success("âœ… æœç´¢æ¨¡å—: å·²åŠ è½½")
        else:
            st.sidebar.warning("âš ï¸ æœç´¢æ¨¡å—: æœªåŠ è½½")

        # åˆ†å·¥4çŠ¶æ€
        if self.topic_graph:
            st.sidebar.success("âœ… è¯é¢˜å›¾æ¨¡å—: å·²åŠ è½½")
        else:
            st.sidebar.warning("âš ï¸ è¯é¢˜å›¾æ¨¡å—: æœªåŠ è½½")

    def _save_api_config(self, api_key, base_url):
        """ä¿å­˜APIé…ç½®"""
        config = {
            "api_key": api_key,
            "base_url": base_url
        }

        config_dir = "config"
        if not os.path.exists(config_dir):
            os.makedirs(config_dir)

        config_file = os.path.join(config_dir, "api_config.json")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)

    def _direct_analyze_file(self, uploaded_file, custom_group_name):
        """è°ƒç”¨åˆ†å·¥1è¿›è¡Œæ–‡ä»¶åˆ†æ"""
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            file_ext = os.path.splitext(uploaded_file.name)[1]
            with tempfile.NamedTemporaryFile(
                    delete=False,
                    suffix=file_ext,
                    dir="temp"
            ) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name

            try:
                # ä½¿ç”¨åˆ†å·¥1è§£ææ–‡ä»¶
                records = self.analyzer.parse_file(tmp_file_path)
                st.info(f"æˆåŠŸè§£æ {len(records)} æ¡è®°å½•")

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒåç§°çš„ç¾¤èŠ
                existing_structure = None
                group_to_replace_index = -1

                if st.session_state.analysis_data:
                    existing_structure = st.session_state.analysis_data
                    # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒåç§°çš„ç¾¤èŠ
                    for i, group in enumerate(existing_structure.get("chat_groups", [])):
                        if group["group_name"] == custom_group_name:
                            group_to_replace_index = i
                            break

                # å¦‚æœæœ‰ç›¸åŒåç§°çš„ç¾¤èŠï¼Œè¦†ç›–å®ƒ
                if group_to_replace_index >= 0:
                    # ç§»é™¤æ—§çš„ç¾¤èŠ
                    existing_structure["chat_groups"].pop(group_to_replace_index)
                    st.info(f"è¦†ç›–å·²å­˜åœ¨çš„ç¾¤èŠ: {custom_group_name}")

                # ç”Ÿæˆè¯é¢˜ç»“æ„
                result = self.analyzer.analyze_topics(
                    group_name=custom_group_name,
                    chat_records=records,
                    existing_structure=existing_structure,
                    description=f"æ¥è‡ªæ–‡ä»¶: {uploaded_file.name}"
                )

                st.success("è¯é¢˜åˆ†æå®Œæˆ")
                return result

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(tmp_file_path):
                    os.unlink(tmp_file_path)

        except Exception as e:
            st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            return None

    def _save_data_to_files(self):
        """ä¿å­˜åˆ†ææ•°æ®åˆ°æ–‡ä»¶ï¼Œä¾›å…¶ä»–åˆ†å·¥ä½¿ç”¨"""
        if not st.session_state.analysis_data:
            return

        # åˆ›å»ºoutputç›®å½•
        data_dir = "output"
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)

        # ä¿å­˜ä¸ºç»Ÿä¸€çš„æ•°æ®æ–‡ä»¶
        data_file = os.path.join(data_dir, "unified_data.json")
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(st.session_state.analysis_data, f, ensure_ascii=False, indent=2)

        # ä¿å­˜ä¸ºæœç´¢æ¨¡å—ä¸“ç”¨æ ¼å¼
        search_data_file = os.path.join(data_dir, "search_data.json")
        search_data = {
            "chat_groups": st.session_state.analysis_data.get("chat_groups", [])
        }
        with open(search_data_file, 'w', encoding='utf-8') as f:
            json.dump(search_data, f, ensure_ascii=False, indent=2)

        # ä¿å­˜ä¸ºè¯é¢˜å›¾æ¨¡å—ä¸“ç”¨æ ¼å¼
        graph_data_file = os.path.join(data_dir, "topic_graph_data.json")
        graph_data = {
            "chat_groups": st.session_state.analysis_data.get("chat_groups", [])
        }
        with open(graph_data_file, 'w', encoding='utf-8') as f:
            json.dump(graph_data, f, ensure_ascii=False, indent=2)

        # æ›´æ–°åˆ†å·¥1å®ä¾‹çš„æ•°æ®
        if self.analyzer:
            self.analyzer.chat_structure = st.session_state.analysis_data

        # æ›´æ–°åˆ†å·¥3å®ä¾‹çš„æ•°æ®ï¼ˆé‡æ–°åŠ è½½ï¼‰
        if self.searcher and os.path.exists(search_data_file):
            try:
                self.searcher.data_file = search_data_file
                self.searcher.data = self.searcher._load_data()
            except:
                pass

        # æ›´æ–°åˆ†å·¥4å®ä¾‹çš„æ•°æ®ï¼ˆé‡æ–°åŠ è½½ï¼‰
        if self.topic_graph and os.path.exists(graph_data_file):
            try:
                self.topic_graph.load_from_json(graph_data_file)
            except:
                pass

        st.session_state.data_file = data_file
        print("âœ… æ•°æ®å·²ä¿å­˜åˆ°outputç›®å½•")

    def call_search_api(self, query: str, search_type: str = "keyword"):
        """ç›´æ¥è°ƒç”¨åˆ†å·¥3çš„æœç´¢åŠŸèƒ½"""
        if not self.searcher:
            st.warning("æœç´¢æ¨¡å—æœªåˆå§‹åŒ–")
            return {"keyword_results": [], "ai_recommendations": []}

        try:
            # è°ƒç”¨åˆ†å·¥3çš„æœç´¢æ–¹æ³•
            search_results = self.searcher.search(
                query=query,
                use_ai=(search_type == "ai_semantic"),
                ai_max_results=10,
                group_name=None,
                topic_name=None,
                use_batch_mode=False,
                batch_size=20
            )

            return search_results

        except Exception as e:
            st.error(f"æœç´¢å¤±è´¥: {str(e)}")
            return {"keyword_results": [], "ai_recommendations": [], "stats": {}}

    def _convert_search_results(self, search_results):
        """å°†æœç´¢APIè¿”å›çš„ç»“æœè½¬æ¢ä¸ºå‰ç«¯æ ¼å¼"""
        converted = []

        # å¤„ç†å…³é”®è¯æœç´¢ç»“æœ
        if 'keyword_results' in search_results:
            for result in search_results['keyword_results']:
                converted.append({
                    'topic_id': result.get('topic_id', ''),
                    'topic_name': result.get('topic_name', ''),
                    'content': result.get('summaries', [''])[0] if result.get('summaries') else '',
                    'sender': result.get('group_info', {}).get('group_name', ''),
                    'score': result.get('search_score', 0) / 10.0,  # å½’ä¸€åŒ–åˆ°0-1
                    'search_type': 'keyword',
                    'priority': result.get('priority', 'ä¸­'),
                    'group_name': result.get('group_info', {}).get('group_name', ''),
                    'group_id': result.get('group_info', {}).get('group_id', '')
                })

        # å¤„ç†AIæ¨èç»“æœ
        if 'ai_recommendations' in search_results:
            for result in search_results['ai_recommendations']:
                topic_info = result.get('topic_info', {})
                converted.append({
                    'topic_id': topic_info.get('topic_id', ''),
                    'topic_name': topic_info.get('topic_name', ''),
                    'content': topic_info.get('summaries', [''])[0] if topic_info.get('summaries') else '',
                    'sender': topic_info.get('group_info', {}).get('group_name', ''),
                    'score': result.get('confidence', 0.5),
                    'search_type': 'ai',
                    'priority': topic_info.get('priority', 'ä¸­'),
                    'group_name': topic_info.get('group_info', {}).get('group_name', ''),
                    'group_id': topic_info.get('group_info', {}).get('group_id', '')
                })

        return converted

    def render_topic_graph(self, data):
        """æ¸²æŸ“è¯é¢˜å…³ç³»å›¾è°±"""
        st.title("ğŸ•¸ï¸ è¯é¢˜å…³ç³»å›¾è°±")

        if not data.get("chat_groups"):
            st.info("è¯·å…ˆä¸Šä¼ èŠå¤©è®°å½•æ–‡ä»¶å¹¶è¿›è¡Œåˆ†æ")
            return

        # æ·»åŠ ç¾¤èŠé€‰æ‹©å™¨
        groups = data["chat_groups"]
        group_options = ["æ‰€æœ‰ç¾¤èŠ"] + [group['group_name'] for group in groups]

        # é»˜è®¤é€‰æ‹©å½“å‰ç¾¤èŠ
        default_index = 0
        if st.session_state.current_group:
            for i, group in enumerate(groups):
                if group["group_id"] == st.session_state.current_group:
                    default_index = i + 1
                    break

        selected_group_index = st.selectbox(
            "é€‰æ‹©ç¾¤èŠ",
            range(len(group_options)),
            format_func=lambda x: group_options[x],
            key="graph_group_select",
            index=default_index
        )

        # è·å–é€‰æ‹©çš„ç¾¤èŠ
        selected_group_name = group_options[selected_group_index]

        # è·å–è¯é¢˜æ•°æ®
        topics = []
        group_name = ""

        if selected_group_name == "æ‰€æœ‰ç¾¤èŠ":
            # åˆå¹¶æ‰€æœ‰è¯é¢˜
            for group in groups:
                topics.extend(group.get("topics", []))
            group_name = "æ‰€æœ‰ç¾¤èŠ"
        else:
            # è·å–æŒ‡å®šç¾¤èŠçš„è¯é¢˜
            for group in groups:
                if group['group_name'] == selected_group_name:
                    topics = group.get("topics", [])
                    group_name = group['group_name']
                    break

        if not topics:
            st.info(f"ç¾¤èŠ '{selected_group_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°è¯é¢˜æ•°æ®")
            return

        st.caption(f"å½“å‰æ˜¾ç¤º: {group_name} ({len(topics)}ä¸ªè¯é¢˜)")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        self._show_graph_statistics(topics, group_name)

        # ä½¿ç”¨åˆ†å·¥4çš„è¯é¢˜å›¾åŠŸèƒ½
        if self.topic_graph:
            try:
                self._render_advanced_topic_graph(topics, group_name)
            except Exception as e:
                st.warning("è¯é¢˜å›¾æ¸²æŸ“é‡åˆ°é—®é¢˜ï¼Œä½¿ç”¨åŸºç¡€è§†å›¾")
                self._render_basic_topic_graph(topics, group_name)
        else:
            # ä½¿ç”¨åŸºç¡€å¯è§†åŒ–
            self._render_basic_topic_graph(topics, group_name)

    def _render_advanced_topic_graph(self, topics, group_name):
        """ä½¿ç”¨åˆ†å·¥4æ¨¡å—æ¸²æŸ“é«˜çº§è¯é¢˜å›¾ï¼ˆç®€åŒ–ç‰ˆï¼Œåˆ é™¤äº†é‡å¤çš„ç»Ÿè®¡ä¿¡æ¯ï¼‰"""
        # æ˜¾ç¤ºè¯é¢˜è¿æ¥è¯¦æƒ…
        if st.checkbox("æ˜¾ç¤ºè¯¦ç»†è¿æ¥", key="show_connections"):
            st.write("**è¯é¢˜è¿æ¥å…³ç³»:**")
            connection_count = 0
            for topic in topics:
                topic_id = topic['topic_id']
                connections = self.topic_graph.graph.get(topic_id, []) if hasattr(self.topic_graph, 'graph') else []
                if connections:
                    connected_names = []
                    for conn_id in connections:
                        conn_name = self.topic_graph.topic_id_to_name.get(conn_id, "æœªçŸ¥è¯é¢˜")
                        if conn_name:
                            connected_names.append(conn_name)

                    if connected_names:
                        st.write(f"- **{topic['topic_name']}** â†’ {', '.join(connected_names)}")
                        connection_count += 1

            if connection_count == 0:
                st.info("æš‚æ— è¿æ¥å…³ç³»")

        self._render_basic_topic_graph(topics, group_name)

    def _render_basic_topic_graph(self, topics, group_name):
        """æ¸²æŸ“åŸºç¡€è¯é¢˜å›¾ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰"""
        # åˆ›å»ºç½‘ç»œå›¾
        G = nx.Graph()

        # æ·»åŠ èŠ‚ç‚¹
        for topic in topics:
            priority_value = {"é«˜": 100, "ä¸­": 70, "ä½": 40}.get(topic.get("priority", "ä¸­"), 50)
            G.add_node(topic['topic_id'],
                       label=topic['topic_name'],
                       size=priority_value,
                       summary=topic.get('summaries', [''])[0],
                       priority=topic.get('priority', 'ä¸­'))

        # æ·»åŠ è¾¹
        edge_count = 0
        for topic in topics:
            topic_id = topic['topic_id']
            for related_topic_name in topic.get("related_topics", []):
                # æŸ¥æ‰¾ç›¸å…³è¯é¢˜çš„ID
                related_topic_id = None
                for t in topics:
                    if t['topic_name'] == related_topic_name:
                        related_topic_id = t['topic_id']
                        break

                if related_topic_id and related_topic_id != topic_id:
                    # è®¡ç®—å…³ç³»å¼ºåº¦
                    strength = 0.5
                    if topic.get("priority") == "é«˜":
                        strength += 0.2
                    if related_topic_name in topic.get("summaries", ["", ""])[0]:
                        strength += 0.3

                    if related_topic_id not in G[topic_id]:
                        G.add_edge(topic_id, related_topic_id,
                                   weight=strength,
                                   description=f"{topic['topic_name']} â†” {related_topic_name}")
                        edge_count += 1

        if len(G.nodes()) == 0:
            st.info("æ²¡æœ‰å¯æ˜¾ç¤ºçš„è¯é¢˜æ•°æ®")
            return

        pos = nx.spring_layout(G, k=1, iterations=50)

        edge_x = []
        edge_y = []
        edge_text = []
        for edge in G.edges(data=True):
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])
            edge_text.append(edge[2].get('description', f"å…³è”å¼ºåº¦: {edge[2].get('weight', 0):.2f}"))

        edge_trace = go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=1.5, color='#888'),
            hoverinfo='text',
            text=edge_text,
            mode='lines')

        node_x = []
        node_y = []
        node_text = []
        node_size = []
        node_color = []
        for node in G.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            node_info = G.nodes[node]
            display_summary = node_info['summary'][:50] + "..." if len(node_info['summary']) > 50 else node_info[
                'summary']
            node_text.append(f"{node_info['label']}<br>ä¼˜å…ˆçº§: {node_info['priority']}<br>æ‘˜è¦: {display_summary}")
            node_size.append(node_info['size'])

            # æ ¹æ®ä¼˜å…ˆçº§è®¾ç½®é¢œè‰²
            priority_color = {
                "é«˜": '#FF6B6B',
                "ä¸­": '#4ECDC4',
                "ä½": '#45B7D1'
            }
            node_color.append(priority_color.get(node_info['priority'], '#45B7D1'))

        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers+text',
            hoverinfo='text',
            text=[G.nodes[node]['label'] for node in G.nodes()],
            textposition="middle center",
            marker=dict(
                size=node_size,
                color=node_color,
                line=dict(width=2, color='darkblue')
            ),
            hovertext=node_text
        )

        fig = go.Figure(data=[edge_trace, node_trace],
                        layout=go.Layout(
                            title=f'è¯é¢˜å…³ç³»ç½‘ç»œ - {group_name}',
                            showlegend=False,
                            hovermode='closest',
                            margin=dict(b=20, l=5, r=5, t=40),
                            annotations=[dict(
                                text="èŠ‚ç‚¹å¤§å°è¡¨ç¤ºä¼˜å…ˆçº§ï¼Œé¢œè‰²è¡¨ç¤ºä¼˜å…ˆçº§ç­‰çº§ï¼ˆçº¢-é«˜ï¼Œé’-ä¸­ï¼Œè“-ä½ï¼‰",
                                showarrow=False,
                                xref="paper", yref="paper",
                                x=0.005, y=-0.002)],
                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))
                        )

        st.plotly_chart(fig, use_container_width=True)

        # å›¾ä¾‹è¯´æ˜
        st.info("ğŸ’¡ **å›¾è§£**: èŠ‚ç‚¹å¤§å°è¡¨ç¤ºè¯é¢˜ä¼˜å…ˆçº§ï¼Œè¿çº¿è¡¨ç¤ºè¯é¢˜ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œè¿çº¿è¶Šç²—è¡¨ç¤ºå…³ç³»å¼ºåº¦è¶Šå¤§")

    def _show_graph_statistics(self, topics, group_name):
        """æ˜¾ç¤ºå›¾ç»“æ„ç»Ÿè®¡ä¿¡æ¯"""
        if not topics:
            return

        try:
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_topics = len(topics)

            # è®¡ç®—ä¼˜å…ˆçº§åˆ†å¸ƒ
            priority_count = {"é«˜": 0, "ä¸­": 0, "ä½": 0}
            for topic in topics:
                priority = topic.get('priority', 'ä¸­')
                priority_count[priority] = priority_count.get(priority, 0) + 1

            total_connections = 0
            connection_pairs = set()

            for topic in topics:
                topic_id = topic['topic_id']
                for related_topic_name in topic.get('related_topics', []):
                    # æŸ¥æ‰¾ç›¸å…³è¯é¢˜ID
                    for t in topics:
                        if t['topic_name'] == related_topic_name:
                            related_topic_id = t['topic_id']
                            # åˆ›å»ºè¿æ¥å¯¹ï¼Œç¡®ä¿æ€»æ˜¯æŒ‰å­—æ¯é¡ºåºæ’åºï¼Œé¿å…é‡å¤è®¡æ•°
                            if topic_id < related_topic_id:
                                pair = (topic_id, related_topic_id)
                            else:
                                pair = (related_topic_id, topic_id)
                            connection_pairs.add(pair)
                            break

            total_connections = len(connection_pairs)

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.subheader("ğŸ“Š è¯é¢˜å›¾ç»Ÿè®¡")
            cols = st.columns(3)
            with cols[0]:
                st.metric("ç¾¤èŠ", group_name)
            with cols[1]:
                st.metric("è¯é¢˜æ€»æ•°", total_topics)
            with cols[2]:
                st.metric("è¿æ¥æ€»æ•°", total_connections)

            # æ˜¾ç¤ºç®€å•çš„ä¼˜å…ˆçº§è®¡æ•°æ–‡æœ¬
            st.write("**è¯é¢˜ä¼˜å…ˆçº§:**")
            cols = st.columns(3)
            with cols[0]:
                st.metric("é«˜ä¼˜å…ˆçº§", priority_count.get("é«˜", 0))
            with cols[1]:
                st.metric("ä¸­ä¼˜å…ˆçº§", priority_count.get("ä¸­", 0))
            with cols[2]:
                st.metric("ä½ä¼˜å…ˆçº§", priority_count.get("ä½", 0))

        except Exception as e:
            st.error(f"æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

    def update_topic(self, topic_id: str, new_summary: str):
        """æ›´æ–°è¯é¢˜ä¿¡æ¯"""
        if not st.session_state.analysis_data:
            return False

        try:
            # æŸ¥æ‰¾å¹¶æ›´æ–°è¯é¢˜
            for group in st.session_state.analysis_data.get("chat_groups", []):
                for topic in group.get("topics", []):
                    if topic['topic_id'] == topic_id:
                        # æ›´æ–°æ‘˜è¦
                        if 'summaries' not in topic:
                            topic['summaries'] = []

                        if topic['summaries']:
                            # æ›´æ–°ç¬¬ä¸€ä¸ªæ‘˜è¦
                            topic['summaries'][0] = new_summary
                        else:
                            topic['summaries'] = [new_summary]

                        # å¦‚æœåˆ†å·¥4æ¨¡å—å­˜åœ¨ï¼Œæ›´æ–°è¯é¢˜å›¾æ•°æ®
                        if self.topic_graph:
                            self._update_topic_in_graph(topic_id, new_summary)

                        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
                        self._save_data_to_files()

                        return True

            return False

        except Exception as e:
            st.error(f"æ›´æ–°è¯é¢˜å¤±è´¥: {str(e)}")
            return False

    def _update_topic_in_graph(self, topic_id, new_summary):
        """æ›´æ–°è¯é¢˜å›¾æ•°æ®"""
        try:
            # é‡æ–°åŠ è½½æ•°æ®
            graph_file = "output/topic_graph_data.json"
            self.topic_graph.load_from_json(graph_file)
        except Exception as e:
            print(f"æ›´æ–°è¯é¢˜å›¾å¤±è´¥: {e}")

    def generate_topic_report(self, topic_id):
        """è°ƒç”¨åˆ†å·¥1ç”ŸæˆæŠ¥å‘Š"""
        if not self.analyzer:
            st.error("åˆ†ææ¨¡å—æœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return None

        try:
            # ç¡®ä¿åˆ†æå™¨ä¸­æœ‰å½“å‰æ•°æ®
            if not self.analyzer.chat_structure:
                self.analyzer.chat_structure = st.session_state.analysis_data

            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            report_content = self.analyzer.generate_report(
                topic_id=topic_id,
                report_type="detailed"
            )

            return report_content

        except Exception as e:
            st.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
            return None

    def render_data_management(self, data):
        """æ¸²æŸ“æ•°æ®ç®¡ç†é¡µé¢"""
        st.title("ğŸ—‘ï¸ æ•°æ®ç®¡ç†")

        if not data.get("chat_groups"):
            st.info("æš‚æ— åˆ†ææ•°æ®")
            return

        st.markdown("### å·²åˆ†æçš„ç¾¤èŠåˆ—è¡¨")

        for i, group in enumerate(data["chat_groups"]):
            with st.expander(f"{group['group_name']} (ID: {group['group_id']}, {len(group.get('topics', []))}ä¸ªè¯é¢˜)"):
                col1, col2, col3 = st.columns([3, 1, 1])

                with col1:
                    st.write(f"**æè¿°:** {group.get('description', 'æš‚æ— æè¿°')}")
                    st.write(f"**åˆ›å»ºæ—¶é—´:** {group.get('created_time', 'æœªçŸ¥')}")

                with col2:
                    if st.button("é€‰æ‹©åˆ é™¤", key=f"select_delete_{group['group_id']}"):
                        st.session_state.selected_group_for_deletion = group['group_id']
                        st.rerun()

                with col3:
                    if st.button("å¯¼å‡ºæ•°æ®", key=f"export_{group['group_id']}"):
                        self._export_group_data(group)

        # åˆ é™¤ç¡®è®¤å¯¹è¯æ¡†
        if st.session_state.selected_group_for_deletion:
            group_to_delete = None
            for group in data["chat_groups"]:
                if group["group_id"] == st.session_state.selected_group_for_deletion:
                    group_to_delete = group
                    break

            if group_to_delete:
                st.markdown("---")
                st.warning(f"âš ï¸ ç¡®å®šè¦åˆ é™¤ç¾¤èŠ **{group_to_delete['group_name']}** çš„æ‰€æœ‰åˆ†ææ•°æ®å—ï¼Ÿ")
                st.write(f"- åŒ…å« {len(group_to_delete.get('topics', []))} ä¸ªè¯é¢˜")
                st.write(f"- æè¿°: {group_to_delete.get('description', 'æš‚æ— æè¿°')}")

                col1, col2 = st.columns(2)
                with col1:
                    if st.button("âœ… ç¡®è®¤åˆ é™¤", type="primary"):
                        self._delete_group_data(group_to_delete["group_id"])
                        st.session_state.selected_group_for_deletion = None
                        st.success("åˆ é™¤æˆåŠŸ")
                        st.rerun()

                with col2:
                    if st.button("âŒ å–æ¶ˆ"):
                        st.session_state.selected_group_for_deletion = None
                        st.rerun()

        # æ‰¹é‡æ“ä½œ
        st.markdown("---")
        st.markdown("### æ‰¹é‡æ“ä½œ")

        if st.button("ğŸ—‘ï¸ åˆ é™¤æ‰€æœ‰åˆ†ææ•°æ®", type="secondary"):
            if st.checkbox("ç¡®è®¤åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œæ­¤æ“ä½œä¸å¯æ¢å¤"):
                self._delete_all_data()
                st.success("æ‰€æœ‰åˆ†ææ•°æ®å·²åˆ é™¤")
                st.rerun()

    def _delete_group_data(self, group_id):
        """åˆ é™¤æŒ‡å®šç¾¤èŠçš„æ•°æ®"""
        if not st.session_state.analysis_data:
            return

        # ä»å†…å­˜æ•°æ®ä¸­åˆ é™¤
        new_groups = []
        for group in st.session_state.analysis_data.get("chat_groups", []):
            if group["group_id"] != group_id:
                new_groups.append(group)

        st.session_state.analysis_data["chat_groups"] = new_groups

        # æ›´æ–°å½“å‰é€‰æ‹©çš„ç¾¤èŠ
        if st.session_state.current_group == group_id:
            if new_groups:
                st.session_state.current_group = new_groups[0]["group_id"]
            else:
                st.session_state.current_group = None

        # é‡æ–°æ„å»ºè¯é¢˜æ˜ å°„
        self._build_topic_mapping()

        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_data_to_files()

    def _delete_all_data(self):
        """åˆ é™¤æ‰€æœ‰åˆ†ææ•°æ®"""
        st.session_state.analysis_data = {"chat_groups": []}
        st.session_state.current_group = None
        st.session_state.topic_mapping = {}

        # æ¸…ç©ºæ–‡ä»¶
        data_files = [
            "output/unified_data.json",
            "output/search_data.json",
            "output/topic_graph_data.json"
        ]

        for file_path in data_files:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    # é‡æ–°åˆ›å»ºç©ºæ–‡ä»¶
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump({"chat_groups": []}, f)
                except:
                    pass

        # é‡æ–°åˆå§‹åŒ–æ¨¡å—
        self.init_modules()

    def _export_group_data(self, group):
        """å¯¼å‡ºç¾¤èŠæ•°æ®"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"group_export_{group['group_name']}_{timestamp}.json"

        export_data = {
            "export_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "group_data": group
        }

        # ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½æ•°æ®",
            data=json.dumps(export_data, ensure_ascii=False, indent=2),
            file_name=filename,
            mime="application/json"
        )

    def load_data(self):
        """åŠ è½½åˆ†ææ•°æ®"""
        if st.session_state.analysis_data is not None:
            return st.session_state.analysis_data

        # å¦‚æœæ²¡æœ‰åˆ†ææ•°æ®ï¼Œæ˜¾ç¤ºç©ºçŠ¶æ€
        return {
            "analysis_info": {
                "total_messages": 0,
                "participants": 0,
                "core_topics": [],
                "main_achievements": [],
                "pending_items": []
            },
            "chat_groups": []
        }

    def _build_topic_mapping(self):
        """æ„å»ºè¯é¢˜IDåˆ°è¯é¢˜åç§°çš„æ˜ å°„å…³ç³»"""
        topic_mapping = {}
        if st.session_state.analysis_data:
            for group in st.session_state.analysis_data.get("chat_groups", []):
                for topic in group.get("topics", []):
                    topic_mapping[topic["topic_id"]] = {
                        "name": topic["topic_name"],
                        "group_id": group["group_id"],
                        "group_name": group["group_name"]
                    }
        st.session_state.topic_mapping = topic_mapping

    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.sidebar.title("ğŸ’¬ ç¾¤èŠåˆ†æç³»ç»Ÿ")
        st.sidebar.markdown("---")

        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = self.handle_file_upload()

        st.sidebar.markdown("---")

        # æ•°æ®æºçŠ¶æ€æ˜¾ç¤º
        if st.session_state.analysis_data is not None:
            groups = st.session_state.analysis_data.get("chat_groups", [])
            if groups:
                st.sidebar.success(f"âœ… å·²åˆ†æ {len(groups)} ä¸ªç¾¤èŠ")
            else:
                st.sidebar.success("âœ… ä½¿ç”¨åˆ†æç»“æœæ•°æ®")
        elif st.session_state.uploaded_file is not None:
            st.sidebar.warning("ğŸ“ æ–‡ä»¶å·²ä¸Šä¼ ï¼Œç­‰å¾…åˆ†æ")
        else:
            st.sidebar.info("ğŸ“‹ è¯·ä¸Šä¼ èŠå¤©è®°å½•æ–‡ä»¶è¿›è¡Œåˆ†æ")

        # ç¾¤èŠé€‰æ‹©
        data = self.load_data()
        groups = data.get("chat_groups", [])
        if len(groups) > 1:
            st.sidebar.markdown("### ğŸ‘¥ é€‰æ‹©ç¾¤èŠ")
            group_options = [f"{group['group_name']} ({len(group.get('topics', []))}ä¸ªè¯é¢˜)" for group in groups]
            selected_group_index = st.sidebar.selectbox(
                "é€‰æ‹©è¦åˆ†æçš„ç¾¤èŠ",
                range(len(groups)),
                format_func=lambda x: group_options[x],
                key="group_selector"
            )
            if selected_group_index is not None:
                st.session_state.current_group = groups[selected_group_index]["group_id"]

        # ç­›é€‰é€‰é¡¹
        st.sidebar.markdown("### ğŸ” ç­›é€‰é€‰é¡¹")
        priority_filter = st.sidebar.multiselect(
            "ä¼˜å…ˆçº§ç­›é€‰",
            ["é«˜", "ä¸­", "ä½"],
            default=["é«˜", "ä¸­", "ä½"],
            key="priority_filter"
        )

        # å¯¼èˆª
        st.sidebar.markdown("### ğŸ§­ å¯¼èˆª")
        page = st.sidebar.radio("é€‰æ‹©é¡µé¢", [
            "ğŸ“Š åˆ†ææ¦‚è§ˆ",
            "ğŸ—‚ï¸ è¯é¢˜æµè§ˆ",
            "ğŸ•¸ï¸ è¯é¢˜å›¾è°±",
            "ğŸ” æ™ºèƒ½æœç´¢",
            "ğŸ—‘ï¸ æ•°æ®ç®¡ç†"
        ], key="page_navigation")

        # é‡ç½®æŒ‰é’®
        st.sidebar.markdown("---")
        if st.sidebar.button("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®", key="reset_all"):
            st.session_state.uploaded_file = None
            st.session_state.analysis_data = None
            st.session_state.current_topic = None
            st.session_state.edit_mode = False
            st.session_state.current_group = None
            st.session_state.topic_mapping = {}
            st.session_state.data_file = None
            st.session_state.custom_group_name = ""
            st.session_state.selected_group_for_deletion = None
            st.session_state.graph_group_select = None  # ä¿®æ”¹ï¼šæ¸…ç©ºè¯é¢˜å›¾è°±é€‰æ‹©å™¨
            st.session_state.last_search_topic = None
            st.session_state.search_expanded_topic_id = None  # æ¸…ç©ºæœç´¢å±•å¼€çš„è¯é¢˜
            st.session_state.search_topic_details = {}  # æ¸…ç©ºæœç´¢è¯é¢˜è¯¦æƒ…
            st.rerun()

        return page, priority_filter

    def render_overview(self, data):
        """æ¸²æŸ“åˆ†ææ¦‚è§ˆé¡µé¢"""
        st.title("ğŸ“Š ç¾¤èŠåˆ†ææ¦‚è§ˆ")

        # æ˜¾ç¤ºæ•°æ®æ¥æºçŠ¶æ€
        if st.session_state.analysis_data is not None:
            groups = data.get("chat_groups", [])
            if groups:
                st.success(f"âœ… å·²æˆåŠŸåˆ†æ {len(groups)} ä¸ªç¾¤èŠ")
            else:
                st.success("âœ… ä½¿ç”¨åˆ†æç»“æœæ•°æ®")
        else:
            st.info("ğŸ“‹ è¯·ä¸Šä¼ èŠå¤©è®°å½•æ–‡ä»¶å¼€å§‹åˆ†æ")

        if not data.get("chat_groups"):
            return

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_messages = 0
        total_topics = 0
        all_topics = []

        for group in data["chat_groups"]:
            for topic in group.get("topics", []):
                total_topics += 1
                total_messages += len(topic.get("related_records", []))
                all_topics.append(topic['topic_name'])

        # å…³é”®æŒ‡æ ‡å¡ç‰‡
        col1, col2 = st.columns(2)

        with col1:
            st.metric("æ€»æ¶ˆæ¯æ•°", f"{total_messages} æ¡")
        with col2:
            st.metric("æ€»è¯é¢˜æ•°", f"{total_topics} ä¸ª")

        st.markdown("---")

        # ç¾¤èŠæ¦‚è§ˆ
        st.subheader("ğŸ‘¥ ç¾¤èŠæ¦‚è§ˆ")
        for group in data["chat_groups"]:
            with st.expander(f"{group['group_name']} ({len(group.get('topics', []))}ä¸ªè¯é¢˜)"):
                st.write(f"**æè¿°**: {group.get('description', 'æš‚æ— æè¿°')}")
                st.write(f"**ç¾¤èŠID**: {group['group_id']}")

                # è¯é¢˜ä¼˜å…ˆçº§ç»Ÿè®¡
                priority_count = {"é«˜": 0, "ä¸­": 0, "ä½": 0}
                for topic in group.get("topics", []):
                    priority = topic.get("priority", "ä¸­")
                    priority_count[priority] = priority_count.get(priority, 0) + 1

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("é«˜ä¼˜å…ˆçº§", priority_count["é«˜"])
                with col2:
                    st.metric("ä¸­ä¼˜å…ˆçº§", priority_count["ä¸­"])
                with col3:
                    st.metric("ä½ä¼˜å…ˆçº§", priority_count["ä½"])

        # åˆ†æç»“æœ
        if data.get("analysis_info", {}).get("main_achievements"):
            st.markdown("---")
            st.subheader("âœ… ä¸»è¦æˆæœ")
            for achievement in data["analysis_info"]["main_achievements"]:
                st.write(f"â€¢ {achievement}")

        if data.get("analysis_info", {}).get("pending_items"):
            st.markdown("---")
            st.subheader("â³ å¾…å†³äº‹é¡¹")
            for pending in data["analysis_info"]["pending_items"]:
                st.write(f"â€¢ {pending}")

    def render_topics_browse(self, data, priority_filter):
        """æ¸²æŸ“è¯é¢˜æµè§ˆé¡µé¢"""
        st.title("ğŸ—‚ï¸ è¯é¢˜æµè§ˆ")

        # æ£€æŸ¥æ˜¯å¦æœ‰æœç´¢è·³è½¬çš„è¯é¢˜
        if st.session_state.last_search_topic:
            st.session_state.current_topic = st.session_state.last_search_topic
            st.session_state.last_search_topic = None

        if not data.get("chat_groups"):
            st.info("è¯·å…ˆä¸Šä¼ èŠå¤©è®°å½•æ–‡ä»¶è¿›è¡Œåˆ†æ")
            return

        # è·å–å½“å‰é€‰æ‹©çš„ç¾¤èŠè¯é¢˜
        current_group_id = st.session_state.current_group
        current_topics = []

        if current_group_id:
            for group in data["chat_groups"]:
                if group["group_id"] == current_group_id:
                    current_topics = group.get("topics", [])
                    st.caption(f"å½“å‰ç¾¤èŠ: {group['group_name']} ({len(current_topics)}ä¸ªè¯é¢˜)")
                    break

        if not current_topics:
            # å¦‚æœæ²¡æœ‰é€‰æ‹©ç‰¹å®šç¾¤èŠæˆ–ç¾¤èŠæ²¡æœ‰è¯é¢˜ï¼Œæ˜¾ç¤ºæ‰€æœ‰è¯é¢˜
            current_topics = []
            for group in data["chat_groups"]:
                current_topics.extend(group.get("topics", []))
            if current_topics:
                st.caption(f"æ˜¾ç¤ºæ‰€æœ‰ç¾¤èŠçš„è¯é¢˜ ({len(current_topics)}ä¸ª)")

        if not current_topics:
            st.info("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è¯é¢˜")
            return

        # è¯é¢˜ç­›é€‰å’Œæ’åº
        col1, col2 = st.columns([3, 1])

        with col1:
            search_term = st.text_input("æœç´¢è¯é¢˜", placeholder="è¾“å…¥å…³é”®è¯æœç´¢...", key="topic_search")

        with col2:
            sort_by = st.selectbox("æ’åºæ–¹å¼", ["ä¼˜å…ˆçº§é™åº", "ç›¸å…³è®°å½•æ•°é™åº", "åç§°æ’åº"], key="topic_sort")

        # è¿‡æ»¤è¯é¢˜
        filtered_topics = []
        for topic in current_topics:
            # ä¼˜å…ˆçº§ç­›é€‰
            topic_priority = topic.get("priority", "ä¸­")
            if priority_filter and topic_priority not in priority_filter:
                continue

            # å…³é”®è¯ç­›é€‰
            if search_term:
                search_lower = search_term.lower()
                name_match = search_lower in topic['topic_name'].lower()
                summary_match = False
                for summary in topic.get("summaries", []):
                    if search_lower in summary.lower():
                        summary_match = True
                        break
                if not (name_match or summary_match):
                    continue

            filtered_topics.append(topic)

        if not filtered_topics:
            st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„çš„è¯é¢˜")
            return

        # æ’åº
        if sort_by == "ä¼˜å…ˆçº§é™åº":
            priority_order = {"é«˜": 3, "ä¸­": 2, "ä½": 1}
            filtered_topics.sort(key=lambda x: priority_order.get(x.get("priority", "ä¸­"), 0), reverse=True)
        elif sort_by == "ç›¸å…³è®°å½•æ•°é™åº":
            filtered_topics.sort(key=lambda x: len(x.get("related_records", [])), reverse=True)
        elif sort_by == "åç§°æ’åº":
            filtered_topics.sort(key=lambda x: x['topic_name'])

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        priority_count = {"é«˜": 0, "ä¸­": 0, "ä½": 0}
        for topic in filtered_topics:
            priority = topic.get("priority", "ä¸­")
            priority_count[priority] = priority_count.get(priority, 0) + 1

        st.write(f"æ˜¾ç¤º {len(filtered_topics)} ä¸ªè¯é¢˜")

        # æ˜¾ç¤ºè¯é¢˜åˆ—è¡¨
        for i, topic in enumerate(filtered_topics):
            self._render_topic_card(topic, i)

    def _render_topic_card(self, topic, index):
        """æ¸²æŸ“å•ä¸ªè¯é¢˜å¡ç‰‡"""
        # æ ¹æ®ä¼˜å…ˆçº§è®¾ç½®é¢œè‰²
        priority_color = {
            "é«˜": "#FF6B6B",
            "ä¸­": "#4ECDC4",
            "ä½": "#45B7D1"
        }
        color = priority_color.get(topic.get("priority", "ä¸­"), "#45B7D1")

        is_expanded = topic['topic_id'] == st.session_state.current_topic

        with st.expander(
                f"ğŸ”¸ {topic['topic_name']} (ä¼˜å…ˆçº§: {topic.get('priority', 'ä¸­')}, ç›¸å…³è®°å½•: {len(topic.get('related_records', []))})",
                expanded=is_expanded):

            col1, col2 = st.columns([3, 1])

            with col1:
                # æ˜¾ç¤ºæ‘˜è¦
                if topic.get("summaries"):
                    st.write(f"**ğŸ“ æ‘˜è¦**: {topic['summaries'][0]}")

                # ç›¸å…³è¯é¢˜é“¾æ¥
                if topic.get("related_topics"):
                    st.write(f"**ğŸ”— ç›¸å…³è¯é¢˜**: {', '.join(topic['related_topics'][:3])}")
                    if len(topic['related_topics']) > 3:
                        st.caption(f"ç­‰{len(topic['related_topics'])}ä¸ªç›¸å…³è¯é¢˜")

            with col2:
                if st.button("æŸ¥çœ‹è¯¦æƒ…", key=f"view_{topic['topic_id']}"):
                    st.session_state.current_topic = topic['topic_id']
                    st.session_state.edit_mode = False
                    st.rerun()

                if st.button("ç¼–è¾‘", key=f"edit_{topic['topic_id']}"):
                    st.session_state.current_topic = topic['topic_id']
                    st.session_state.edit_mode = True
                    st.rerun()

            # å¦‚æœå½“å‰è¯é¢˜è¢«é€‰ä¸­ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if st.session_state.current_topic == topic['topic_id']:
                self._render_topic_detail(topic)

    def _render_topic_detail(self, topic):
        """æ¸²æŸ“è¯é¢˜è¯¦ç»†ä¿¡æ¯"""
        st.markdown("---")
        st.subheader(f"ğŸ’¬ {topic['topic_name']} çš„è¯¦ç»†è®°å½•")

        if st.session_state.edit_mode:
            # ç¼–è¾‘æ¨¡å¼
            current_summary = topic['summaries'][0] if topic.get('summaries') else ""
            new_summary = st.text_area("è¯é¢˜æ‘˜è¦", value=current_summary, height=100,
                                       key=f"edit_summary_{topic['topic_id']}")

            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", key=f"save_{topic['topic_id']}"):
                    if self.update_topic(topic['topic_id'], new_summary):
                        st.success("ä¿å­˜æˆåŠŸ")
                        st.session_state.edit_mode = False
                        st.rerun()
            with col2:
                if st.button("ğŸ“„ ç”ŸæˆæŠ¥å‘Š", key=f"report_{topic['topic_id']}"):
                    report_content = self.generate_topic_report(topic['topic_id'])
                    if report_content:
                        with st.expander("ğŸ“‹ è¯é¢˜åˆ†ææŠ¥å‘Š", expanded=True):
                            st.markdown(report_content)

                        # æä¾›ä¸‹è½½æŒ‰é’®
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        report_text = f"""# è¯é¢˜åˆ†ææŠ¥å‘Š
## è¯é¢˜åç§°: {topic['topic_name']}
## è¯é¢˜ID: {topic['topic_id']}
## ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

{report_content}
"""
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æŠ¥å‘Š",
                            data=report_text,
                            file_name=f"topic_report_{topic['topic_id']}_{timestamp}.md",
                            mime="text/markdown"
                        )
            with col3:
                if st.button("âŒ å–æ¶ˆ", key=f"cancel_{topic['topic_id']}"):
                    st.session_state.edit_mode = False
                    st.rerun()
        else:
            # æŸ¥çœ‹æ¨¡å¼
            # æ˜¾ç¤ºæ‰€æœ‰æ‘˜è¦
            if topic.get("summaries"):
                st.write("**è¯é¢˜æ‘˜è¦:**")
                for i, summary in enumerate(topic['summaries'], 1):
                    st.write(f"{i}. {summary}")

            # æ˜¾ç¤ºç›¸å…³èŠå¤©è®°å½•
            if topic.get("related_records"):
                st.write("**ç›¸å…³èŠå¤©è®°å½•:**")
                for record in topic.get("related_records", []):
                    if isinstance(record, str):
                        if "ï¼š" in record:
                            parts = record.split("ï¼š", 1)
                            if len(parts) == 2:
                                st.write(f"**{parts[0]}**: {parts[1]}")
                            else:
                                st.write(f"{record}")
                        elif ":" in record:
                            parts = record.split(":", 1)
                            if len(parts) == 2:
                                st.write(f"**{parts[0]}**: {parts[1]}")
                            else:
                                st.write(f"{record}")
                        else:
                            st.write(f"{record}")

            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("è¿”å›åˆ—è¡¨", key=f"back_{topic['topic_id']}"):
                    st.session_state.current_topic = None
                    st.rerun()
            with col2:
                if st.button("ç¼–è¾‘è¯é¢˜", key=f"edit_btn_{topic['topic_id']}"):
                    st.session_state.edit_mode = True
                    st.rerun()
            with col3:
                if st.button("ç”ŸæˆæŠ¥å‘Š", key=f"gen_report_{topic['topic_id']}"):
                    report_content = self.generate_topic_report(topic['topic_id'])
                    if report_content:
                        with st.expander("ğŸ“‹ è¯é¢˜åˆ†ææŠ¥å‘Š", expanded=True):
                            st.markdown(report_content)

                        # æä¾›ä¸‹è½½æŒ‰é’®
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        report_text = f"""# è¯é¢˜åˆ†ææŠ¥å‘Š
## è¯é¢˜åç§°: {topic['topic_name']}
## è¯é¢˜ID: {topic['topic_id']}
## ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-d %H:%M:%S")}

{report_content}
"""
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æŠ¥å‘Š",
                            data=report_text,
                            file_name=f"topic_report_{topic['topic_id']}_{timestamp}.md",
                            mime="text/markdown"
                        )

    def render_search(self, data):
        """æ¸²æŸ“æ™ºèƒ½æœç´¢é¡µé¢"""
        st.title("ğŸ” æ™ºèƒ½æœç´¢")

        if not data.get("chat_groups"):
            st.info("è¯·å…ˆä¸Šä¼ èŠå¤©è®°å½•æ–‡ä»¶è¿›è¡Œåˆ†æ")
            return

        # æœç´¢è¾“å…¥
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            search_query = st.text_input("è¾“å…¥æœç´¢å†…å®¹", placeholder="è¾“å…¥å…³é”®è¯æˆ–å®Œæ•´å¥å­...", key="search_input")
        with col2:
            search_type = st.selectbox("æœç´¢ç±»å‹", ["å…³é”®è¯", "è¯­ä¹‰"], key="search_type")
        with col3:
            st.write("")
            st.write("")
            search_button = st.button("å¼€å§‹æœç´¢", type="primary", key="search_button")

        if search_button and search_query:
            st.write(f"æ­£åœ¨æœç´¢: `{search_query}`")

            # è°ƒç”¨åˆ†å·¥3çš„æœç´¢API
            with st.spinner("æ­£åœ¨æœç´¢..."):
                search_type_param = "keyword" if search_type == "å…³é”®è¯" else "ai_semantic"
                search_results = self.call_search_api(search_query, search_type_param)

            if search_results and "keyword_results" in search_results:
                # è½¬æ¢æœç´¢ç»“æœ
                formatted_results = self._convert_search_results(search_results)

                if formatted_results:
                    # æŒ‰è¯é¢˜åˆ†ç»„æ˜¾ç¤ºç»“æœ
                    results_by_topic = {}
                    for result in formatted_results:
                        topic_id = result['topic_id']
                        if topic_id not in results_by_topic:
                            results_by_topic[topic_id] = {
                                'topic_name': result['topic_name'],
                                'topic_id': topic_id,
                                'group_name': result.get('group_name', ''),
                                'priority': result.get('priority', 'ä¸­'),
                                'results': [],
                                'max_score': result['score']
                            }
                        results_by_topic[topic_id]['results'].append(result)
                        if result['score'] > results_by_topic[topic_id]['max_score']:
                            results_by_topic[topic_id]['max_score'] = result['score']

                    # æŒ‰æœ€é«˜åˆ†æ’åº
                    sorted_topics = sorted(results_by_topic.items(),
                                           key=lambda x: x[1]['max_score'],
                                           reverse=True)

                    st.success(f"æ‰¾åˆ° {len(formatted_results)} æ¡ç›¸å…³ç»“æœï¼Œåˆ†å¸ƒåœ¨ {len(sorted_topics)} ä¸ªè¯é¢˜ä¸­")

                    for topic_id, topic_data in sorted_topics:
                        with st.expander(
                                f"ğŸ“Œ {topic_data['topic_name']} (ç›¸å…³åº¦: {topic_data['max_score']:.2f}, {len(topic_data['results'])}æ¡ç»“æœ)"):
                            # æ˜¾ç¤ºè¯é¢˜åŸºæœ¬ä¿¡æ¯
                            st.write(f"**ç¾¤èŠ**: {topic_data['group_name']}")
                            st.write(f"**ä¼˜å…ˆçº§**: {topic_data['priority']}")

                            # æ˜¾ç¤ºæœç´¢ç»“æœ
                            for i, result in enumerate(topic_data['results']):
                                st.write(f"**åŒ¹é…å†…å®¹**: {result['content']}")
                                st.write(
                                    f"**æœç´¢ç±»å‹**: {'å…³é”®è¯åŒ¹é…' if result['search_type'] == 'keyword' else 'è¯­ä¹‰åŒ¹é…'}")
                                st.write(f"**ç›¸å…³åº¦**: {result['score']:.2f}")

                                if i < len(topic_data['results']) - 1:
                                    st.divider()

                            # è·å–è¯é¢˜è¯¦æƒ…
                            topic = None
                            for group in data.get("chat_groups", []):
                                for t in group.get("topics", []):
                                    if t["topic_id"] == topic_id:
                                        topic = t
                                        break
                                if topic:
                                    break

                            if topic:
                                with st.expander("ğŸ“– æŸ¥çœ‹èŠå¤©è®°å½•è¯¦æƒ…", expanded=False):
                                    self._render_search_topic_records(topic)

                else:
                    st.warning("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ")
            else:
                st.warning("æœç´¢æœåŠ¡è¿”å›ç©ºç»“æœæˆ–å‘ç”Ÿé”™è¯¯")

    def _render_search_topic_records(self, topic):
        """åœ¨æœç´¢é¡µé¢æ¸²æŸ“è¯é¢˜èŠå¤©è®°å½•"""
        # é—®é¢˜1ï¼šä¸éœ€è¦ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼Œåªæ˜¾ç¤ºèŠå¤©è®°å½•
        # æ˜¾ç¤ºæ‰€æœ‰æ‘˜è¦
        if topic.get("summaries"):
            st.write("**è¯é¢˜æ‘˜è¦:**")
            for i, summary in enumerate(topic['summaries'], 1):
                st.write(f"{i}. {summary}")

        # æ˜¾ç¤ºç›¸å…³èŠå¤©è®°å½•
        if topic.get("related_records"):
            st.write("**ç›¸å…³èŠå¤©è®°å½•:**")
            for record in topic.get("related_records", []):
                if isinstance(record, str):
                    if "ï¼š" in record:
                        parts = record.split("ï¼š", 1)
                        if len(parts) == 2:
                            st.write(f"**{parts[0]}**: {parts[1]}")
                        else:
                            st.write(f"{record}")
                    elif ":" in record:
                        parts = record.split(":", 1)
                        if len(parts) == 2:
                            st.write(f"**{parts[0]}**: {parts[1]}")
                        else:
                            st.write(f"{record}")
                    else:
                        st.write(f"{record}")

    def run(self):
        """è¿è¡Œä¸»åº”ç”¨"""
        # åŠ è½½æ•°æ®
        data = self.load_data()

        # æ¸²æŸ“ä¾§è¾¹æ å¹¶è·å–å½“å‰é¡µé¢
        page, priority_filter = self.render_sidebar()

        # æ ¹æ®é€‰æ‹©æ¸²æŸ“ä¸åŒé¡µé¢
        if page == "ğŸ“Š åˆ†ææ¦‚è§ˆ":
            self.render_overview(data)
        elif page == "ğŸ—‚ï¸ è¯é¢˜æµè§ˆ":
            self.render_topics_browse(data, priority_filter)
        elif page == "ğŸ•¸ï¸ è¯é¢˜å›¾è°±":
            self.render_topic_graph(data)
        elif page == "ğŸ” æ™ºèƒ½æœç´¢":
            self.render_search(data)
        elif page == "ğŸ—‘ï¸ æ•°æ®ç®¡ç†":  # æ–°å¢é¡µé¢
            self.render_data_management(data)


if __name__ == "__main__":
    # åˆå§‹åŒ–é¡µé¢é…ç½®
    st.set_page_config(
        page_title="ç¾¤èŠåˆ†æç³»ç»Ÿ",
        page_icon="ğŸ’¬",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # æ˜¾ç¤ºæ ‡é¢˜å’Œè¯´æ˜
    st.title("ğŸ’¬ ç¾¤èŠåˆ†æç³»ç»Ÿ")
    st.markdown("""\
    ### ä½¿ç”¨æ­¥éª¤
    1. åœ¨å·¦ä¾§è¾“å…¥APIå¯†é’¥
    2. ä¸Šä¼ èŠå¤©è®°å½•æ–‡ä»¶ï¼ˆæ”¯æŒPDFã€DOCã€DOCXæ ¼å¼ï¼‰
    3. ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®è¿›è¡Œåˆ†æ
    4. ä½¿ç”¨ä¸åŒé¡µé¢æŸ¥çœ‹åˆ†æç»“æœ

    ### æ¨¡å—çŠ¶æ€
    é¡µé¢å·¦ä¾§ä¼šæ˜¾ç¤ºå„æ¨¡å—çš„åŠ è½½çŠ¶æ€ï¼Œç¡®ä¿æ‰€æœ‰æ¨¡å—æ­£å¸¸åŠ è½½ä»¥è·å¾—å®Œæ•´åŠŸèƒ½ã€‚
    """)

    # åˆ›å»ºå‰ç«¯ç®¡ç†å™¨å®ä¾‹å¹¶è¿è¡Œ
    try:
        frontend = FrontendManager()
        frontend.run()
    except Exception as e:
        if "list indices must be integers or slices, not NoneType" in str(e):
            st.info("è¯·é€‰æ‹©ç¾¤èŠï¼Œæˆ–è€…ç­‰å¾…ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚")
        else:
            st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.info("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–æ¨¡å—ï¼ˆanalyzer.py, searcher.py, topic_graph.pyï¼‰åœ¨å½“å‰ç›®å½•ä¸‹")